---
title: "Anomaly Detection in Ontario's 2019 Sunshine List"
author: "William Au"
date: "June 4, 2021"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction
Each year, the Ontario government publishes its "Sunshine List" of highest income earners among its public servants, which is defined as those earning over $100,000 annually. This data is intended to facilitate transparency and accountability.

Anomaly detection refers to techniques that detect outliers, rare events, unusual data, etc. Using unsupervised machine learning algorithms for anomaly detection is a common technique. In this project, I use density-based spatial clustering of applications with noise (DBSCAN) to detect anomalies in Ontario's Sunshine List. 

The motivation for anomaly detection on the List is for 3 reasons:

* Uncover possible data entry errors, such as erroneously adding an extra digit to a salary
* Discover instances of compensation that may be out-of-policy
* Highlight possible instances of cronyism, nepotism or other politically corrupt compensation practices

DBSCAN is a non-parametric, and can detect anomalies even if they do not cluster in a spherical shape or lie close to large numbers of observations. Because of these advantages, it is an excellent technique in this analysis because corrupt compensation practices might be intentionally hidden, leading to non-spherical clusters or nearness to non-anomalous clusters in high-dimensional data.

```{r admin, message = FALSE, warning = FALSE, results = "hide", include = FALSE}
# ----- admin -----
rm(list = ls())  # clear environment
library(rmarkdown)  # markdown
library(knitr)  # knitr
library(tidyverse)  # for tidy data import and wrangling
library(factoextra)  # for cluster visualization
library(fpc)  # for dbscan clustering
library(caret)  # for dummy variables
library(cluster)  # for clustering
library(GGally)  # for matrix plotting
library(RColorBrewer)  # for color palettes
library(scales)
library(ClusterR)
memory.limit(size = 16141 * 4)
gc()  # garbage collection

# import 2019 data
s01 <- as_tibble(read_csv(
    "tbs-pssd-compendium-2019-en-2020-12-21.csv", 
    col_names = TRUE)) %>%
    mutate(
        salary = readr::parse_number(`Salary Paid`),
        taxable_ben = readr::parse_number(`Taxable Benefits`)) %>%
    select(-c(`Salary Paid`, `Taxable Benefits`))

```

Below is the results of my exploratory data analysis. There are some insights by sector, including:

* The highest salaries are in Ontario Power Generation
* Seconded and school board employees have generally lower salaries
* University staff have generally higher salaries than colleges
* Taxable benefits are often low, but can rarely be extremely high, especially for hospitals and public health boards
* Taxable benefits is only 23% correlated with salary, which is lower than I expect

```{r eda, message = FALSE, warning = FALSE, echo = FALSE, include = TRUE}
# EDA - sector (18), employer >1000
ggplot(
    data = s01,
    aes(
        x = Sector,
        y = salary)) +
    geom_violin(trim = FALSE, fill = "green") + 
    coord_flip() +
    scale_y_continuous(name = "Salary", labels = comma) +
    theme_minimal()
ggplot(
    data = s01,
    aes(
        x = Sector,
        y = taxable_ben)) +
    geom_violin(trim = FALSE, fill = "green") + 
    coord_flip() +
    scale_y_continuous(name = "Taxable benefits", labels = comma) +
    theme_minimal()
tmp <- s01 %>%
    sample_n(size = 500, replace = FALSE)
ggpairs(
    data = tmp,
    columns = 7:8,
    aes(
        alpha = 0.1),
    upper = list("cor")) + 
    theme_minimal()
```

Because DBSCAN is a memory-intensive algorithm, it could not be implemented on the entire Sunshine List on commodity hardware. So I build a heuristic using the more efficient k-means clustering algorithm, assigning each public servant to one of 1,000 k-means cluster, a large enough number such that anomalies should be grouped together but small enough for processing on commodity hardware. Then DBSCAN was processed on the reduced data set of 1,000 k-means clusters.

A popular method for hyperparameter tuning for DBSCAN was using a k-nearest neighbour plot and varying k for the minimum number of members in a cluster and interpreting the plots for an elbow point for a hypothetical radius parameter. Because of the nature of the project, I set the minimum number of observations per cluster as a low 1. 

The plots below depict the final iteration of hyperparameter tuning attempts (6 tuning attempts were attempted to discriminate between anomalous and non-anomalous observations). For the final model, I noted elbow points at radius parameters of 1,000,000 where the minimum number of points per cluster is 400.

```{r trans_tune, message = FALSE, warning = FALSE, echo = FALSE, include = TRUE}
# kmeans for data reduction
set.seed(888)
tmp_km <- kmeans(s01[, 7:8], centers = 1000, nstart = 10, trace = FALSE)
tmp_ctr <- as_tibble(tmp_km$centers)
tmp_clus <- as_tibble(tmp_km$cluster)
s02_dist <- daisy(tmp_ctr, metric = "euclidean")

# ----- tune hyperparameters for dbscan clustering -----
tmp <- dbscan::kNNdist(s02_dist, k = 400, all = TRUE)
dbscan::kNNdistplot(tmp, k = 400)
abline(h = 1000000, lty = 2, col = "red")  # eps = 1000
```

The print below shows the distribution between anomalous (db_cluster = 0) and non-anomalous clusters (db_cluster = 1). The anomalies are about 6% of all public servants in the List.

```{r model, message = FALSE, warning = FALSE, echo = FALSE, include = TRUE}
# modeling
set.seed(888)
s03_clus <- fpc::dbscan(
    data = s02_dist, 
    eps = 1000000,
    MinPts = 400,
    scale = FALSE,
    method = "hybrid",
    seeds = FALSE,
    showplot = FALSE,
    countmode = NULL)

# use dbscan to score kmeans, then assign back to obs
centers <- as.matrix(tmp_km$centers)
tmp2 <- s01 %>%
    bind_cols(as_tibble(as.vector(ClusterR::predict_KMeans(data = s01[, 7:8], 
    CENTROIDS = centers, threads = 1)))) %>%
    mutate(km_cluster = as.character(value)) %>%
    select(-value) 
tmp3 <- as_tibble(s03_clus$cluster) %>%
    mutate(db_cluster = as.character(value),
        km_cluster = as.character(row_number())) %>%
    select(-value)
s04_clus <- tmp2 %>%
    left_join(tmp3, by = "km_cluster")
s04_clus %>% group_by(db_cluster) %>% count() %>% arrange(n) %>% print() # 0.94%
```

After modeling, the plots below show some insights between anomalous and non-anomalous public servants:

* Not only do the anomalies have almost universally higher salaries, but their highest salaries are orders of magnitude higher than the non-anomalous
* Even in anomalies, taxable benefits are often low; however, the most extreme of these can be greater than $300,000 in a year
* Anomalies are most often driven by higher salaries, as opposed to taxable benefits, but a very few number of anomalies have huge taxable benefits; a small number of anomalies also are driven by a combination of high salary and high taxable benefits

```{r viz, message = FALSE, warning = FALSE, echo = FALSE, include = TRUE}
ggplot(
    data = s04_clus,
    aes(
        x = db_cluster,
        y = salary)) +
    geom_violin(trim = FALSE, fill = "green") + 
    coord_flip() +
    scale_y_continuous(name = "Salary", labels = comma) +
    stat_summary(fun.data = mean_sdl, geom = "pointrange", color = "red") +
    theme_minimal()
ggplot(
    data = s04_clus,
    aes(
        x = db_cluster,
        y = taxable_ben)) +
    geom_violin(trim = FALSE, fill = "green") + 
    coord_flip() +
    scale_y_continuous(name = "Taxable benefits", labels = comma) +
    stat_summary(fun.data = mean_sdl, geom = "pointrange", color = "red") +
    theme_minimal()


tmp_plt <- s04_clus %>%
    sample_n(size = 100000, replace = FALSE)
ggplot(tmp_plt,
    aes(x = taxable_ben, y = salary, group = db_cluster)) +
    geom_point(aes(color = db_cluster)) + theme_minimal()
tmp_pca <- prcomp(s01[, 7:8], scale = TRUE)
fviz_pca_biplot(tmp_pca, label = "var", habillage = s04_clus$db_cluster,
               addEllipses = FALSE, ellipse.level = 0.95)
fviz_cluster(s03_clus, data = s02_dist, stand = TRUE, ellipse = TRUE, 
    show.clust.cent = TRUE, palette = "paired", geom = "point", pointsize = 1,
    repel = TRUE, ggtheme = theme_minimal()) + coord_fixed() 
```

So who were the top anomalies? Here are the top 10 by salary, taxable benefits and a combination of the two.

```{r hit_list, message = FALSE, warning = FALSE, echo = FALSE, include = TRUE}
print("Top 10 public servants with the highest salaries")
s04_clus %>%
    filter(db_cluster == "0") %>%
    select(-`Calendar Year`, -km_cluster, -taxable_ben, -db_cluster) %>%
    arrange(desc(salary)) %>%
    head(10)
print("Top 10 public servants with the highest taxable benefits")
s04_clus %>%
    filter(db_cluster == "0") %>%
    select(-`Calendar Year`, -km_cluster, -salary, -db_cluster) %>%
    arrange(desc(taxable_ben)) %>%
    head(10)
print("Top 10 public servants with the highest combined compensation")
s04_clus %>%
    filter(db_cluster == "0") %>%
    mutate(total_comp = salary + taxable_ben) %>%
    select(-`Calendar Year`, -km_cluster, -salary, -taxable_ben, -db_cluster) %>%
    arrange(desc(total_comp)) %>%
    head(10)